main_output_dir: 'runs/glue_debug'
load_from_zoo: "no"

evaluate_locals_before: true
evaluate_locals_after: true
evaluate_global_model: false
evaluate_locals_ood: false
evaluate_global_joint: false

mtl: true
mtl_all_tasks: true

templates:
  dataset: "glue"

local_models:
  output_dir_format: '{main_output_dir}/local_models/{name}'
  _mtl_models: {} # this will be 'models' after preprocess
      #mtl_model0:
      #  components: ['model0', 'model1']
      #mtl_model1:
      #  components: ['model2', 'model3']
  models: # this will be '_models' after preprocess
      model0:
        task_type: classification
        dataset_name: cola
        partition: -1
        device: 'cuda:0'
      model1:
        task_type: classification
        dataset_name: sst2
        partition: -1
        device: 'cuda:0'
      model2:
        task_type: classification
        dataset_name: mrpc
        partition: -1
        device: 'cuda:0'
      model3:
        task_type: classification
        dataset_name: stsb
        partition: -1
        device: 'cuda:0'
        is_regression: true
      model4:
        task_type: classification
        dataset_name: mnli
        partition: -1
        device: 'cuda:0'
      model5:
        task_type: classification
        dataset_name: qnli
        partition: -1
        device: 'cuda:0'
      model6:
        task_type: classification
        dataset_name: qqp
        partition: -1
        device: 'cuda:0'
      model7:
        task_type: classification
        dataset_name: rte
        partition: -1
        device: 'cuda:0'
      model8:
        task_type: classification
        dataset_name: wnli
        partition: -1
        device: 'cuda:0'


merger:
  exclude_param_regex: ['.*pre_classifier.*','.*classifier.*']
  

tokenizer: "{resource_dir}/distilbert-base-uncased"
model_type: distilbert

# for debug


global_device: 'cuda:0'
dataset: "{dataset}"
partition_method: "uniform"


# from fednlp: model_args
default_model_args:
  # just for debugging
  is_regression: false
  num_train_epochs: 3.0
  do_lower_case: true
  per_device_eval_batch_size: 32
  fp16: false
  gradient_accumulation_steps: 1
  learning_rate: 2.0e-5
  local_rank: -1
  max_grad_norm: 1.0
  max_seq_length: 128
  model_type: null
  save_total_limit: 2
  max_steps: -1
  per_device_train_batch_size: 32
  use_multiprocessing: false # dataloader
  labels_map: {}
  regression: false
  version: 0


